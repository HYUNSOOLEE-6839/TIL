{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 반복 실험을 위한 Sacred\n",
    "- Sacred란?\n",
    "    - Sacred is a tool to help you configure, organize, log and reproduce experiments developed at IDSIA\n",
    "    - 머신러닝 모델링을 진행할 때 설정을 저장해주고 관리하는 것을 도와주는 도구\n",
    "- 왜 필요한가요?\n",
    "    - Kaggle에서 자주 발생하는 예시\n",
    "        - 사용한 Feature는?\n",
    "        - 사용한 파라미터는?\n",
    "        - 그 결과는?\n",
    "    - 다양한 실험을 빠르게 진행하며, 손으로 기록하지 않고 자동으로 기록될 수 있도록 도와줄 도구가 필요\n",
    "- Scratch로 구현하면?\n",
    "    - Logger를 정의해서 필요할 때마다 Logger에 Feature, 파라미터 등을 저장\n",
    "    - 값을 보기 위해 Logger를 Parsing\n",
    "- Sacred는 위 방법을 데코레이터로 쉽게 사용할 수 있도록 도와줌\n",
    "    - MLOps와 관련되는 부분으로, 국내의 다양한 머신러닝 강의에서 이런 부분을 다루지 않아 추가!\n",
    "    \n",
    "    <br>\n",
    "- Sacred의 Main mechanisms\n",
    "    - ConfigScopes : 함수의 local 변수를 편리하게 다룰 수 있음 @ex.config 데코레이터로 사용\n",
    "    - Config Injection : 모든 함수에 있는 설정을 접근할 수 있음\n",
    "    - Command-line interface : 커맨드 라인으로 파라미터를 바꿔서 실행할 수 있음\n",
    "    - Observers : 실험의 모든 정보를 Observers에게 제공해 저장. MongoDB / S3 등 => 이번 강의에선 그냥 로컬에 저장\n",
    "    - Automatic seeding : 실험의 무작위를 컨트롤할 때 도와줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "from numpy.random import permutation\n",
    "from sklearn import svm, datasets\n",
    "from sacred import Experiment\n",
    "from sacred.observers import FileStorageObserver\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "warnings.filterwarnings('ignore')\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "PROJECT_ID='predictfornyctaxi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scared 공식 홈페이지 예시(다른 사람이 작성한 코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook에선 interactive=True 지정해줘야 하고, 스크립트 형식이라면 이 옵션이 필요 없음\n",
    "ex = Experiment('iris_rbf_svm', interactive=True)\n",
    "\n",
    "# Decorator로 config 저장\n",
    "@ex.config\n",
    "def cfg():\n",
    "    C = 1.0\n",
    "    gamma = 0.7\n",
    "\n",
    "# ex.main을 지정 => 이 때 cfg에 있는 인자들이 자동으로 injection됨\n",
    "# 또한 Notebook에선 ex.main을 쓰고 스크립트 파일에선 ex.automain을 사용\n",
    "@ex.main\n",
    "def run(C, gamma):\n",
    "    iris = datasets.load_iris()\n",
    "    per = permutation(iris.target.size)\n",
    "    iris.data = iris.data[per]\n",
    "    iris.target = iris.target[per]\n",
    "    clf = svm.SVC(C, 'rbf', gamma=gamma)\n",
    "    clf.fit(iris.data[:90],\n",
    "          iris.target[:90])\n",
    "    return clf.score(iris.data[90:],\n",
    "                   iris.target[90:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - iris_rbf_svm - No observers have been added to this run\n",
      "INFO - iris_rbf_svm - Running command 'run'\n",
      "INFO - iris_rbf_svm - Started\n",
      "INFO - iris_rbf_svm - Result: 0.9833333333333333\n",
      "INFO - iris_rbf_svm - Completed after 0:00:00\n"
     ]
    }
   ],
   "source": [
    "run_result = ex.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'gamma': 0.7, 'seed': 717118411}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_result.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833333333333333"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_result.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'iris_rbf_svm',\n",
       " 'base_dir': '/Users/hyunsoolee/Documents/GitHub/TIL/Day-24',\n",
       " 'sources': [],\n",
       " 'dependencies': ['ipython==7.19.0',\n",
       "  'ipywidgets==7.5.1',\n",
       "  'matplotlib==3.3.2',\n",
       "  'numpy==1.19.2',\n",
       "  'pandas==1.1.3',\n",
       "  'sacred==0.8.2',\n",
       "  'scikit-learn==0.23.2',\n",
       "  'seaborn==0.11.0'],\n",
       " 'repositories': [],\n",
       " 'mainfile': None}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_result.experiment_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기존 프로젝트에 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = Experiment('nyc-demand-prediction', interactive=True)\n",
    "\n",
    "# experiment_dir가 없으면 폴더 생성하고 FileStorageObserver로 저장\n",
    "experiment_dir = os.path.join('./', 'experiments')\n",
    "if not os.path.isdir(experiment_dir): \n",
    "    os.makedirs(experiment_dir)\n",
    "ex.observers.append(FileStorageObserver.create(experiment_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - pandas_gbq.gbq - Total time taken 7.71 s.\n",
      "Finished at 2021-03-25 16:16:06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.64 s, sys: 123 ms, total: 1.77 s\n",
      "Wall time: 7.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_query = \"\"\"\n",
    "WITH base_data AS \n",
    "(\n",
    "  SELECT nyc_taxi.*, gis.* EXCEPT (zip_code_geom)\n",
    "  FROM (\n",
    "    SELECT *\n",
    "    FROM `bigquery-public-data.new_york_taxi_trips.tlc_yellow_trips_2015`\n",
    "    WHERE \n",
    "        EXTRACT(MONTH from pickup_datetime) = 1\n",
    "        and pickup_latitude  <= 90 and pickup_latitude >= -90\n",
    "    ) AS nyc_taxi\n",
    "  JOIN (\n",
    "    SELECT zip_code, state_code, state_name, city, county, zip_code_geom\n",
    "    FROM `bigquery-public-data.geo_us_boundaries.zip_codes`\n",
    "    WHERE state_code='NY'\n",
    "    ) AS gis \n",
    "  ON ST_CONTAINS(zip_code_geom, st_geogpoint(pickup_longitude, pickup_latitude))\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    zip_code,\n",
    "    DATETIME_TRUNC(pickup_datetime, hour) as pickup_hour,\n",
    "    EXTRACT(MONTH FROM pickup_datetime) AS month,\n",
    "    EXTRACT(DAY FROM pickup_datetime) AS day,\n",
    "    CAST(format_datetime('%u', pickup_datetime) AS INT64) -1 AS weekday,\n",
    "    EXTRACT(HOUR FROM pickup_datetime) AS hour,\n",
    "    CASE WHEN CAST(FORMAT_DATETIME('%u', pickup_datetime) AS INT64) IN (6, 7) THEN 1 ELSE 0 END AS is_weekend,\n",
    "    COUNT(*) AS cnt\n",
    "FROM base_data \n",
    "GROUP BY zip_code, pickup_hour, month, day, weekday, hour, is_weekend\n",
    "ORDER BY pickup_hour\n",
    "\"\"\"\n",
    "\n",
    "base_df = pd.read_gbq(query=base_query, dialect='standard', project_id=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(base_df[['zip_code']])\n",
    "ohe_output = enc.transform(base_df[['zip_code']]).toarray()\n",
    "ohe_df = pd.concat([base_df, pd.DataFrame(ohe_output, columns='zip_code_'+enc.categories_[0])], axis=1)\n",
    "ohe_df['log_cnt'] = np.log10(ohe_df['cnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_and_test(df, date):\n",
    "    \"\"\"\n",
    "    Dataframe에서 train_df, test_df로 나눠주는 함수\n",
    "    \n",
    "    df : 시계열 데이터 프레임\n",
    "    date : 기준점 날짜\n",
    "    \"\"\"\n",
    "    train_df = df[df['pickup_hour'] < date]\n",
    "    test_df = df[df['pickup_hour'] >= date]\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = split_train_and_test(ohe_df, '2015-01-24')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사용하지 않을 컬럼 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df['zip_code']\n",
    "del train_df['pickup_hour']\n",
    "del test_df['zip_code']\n",
    "del test_df['pickup_hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_raw = train_df.pop('cnt')\n",
    "y_train_log = train_df.pop('log_cnt')\n",
    "y_test_raw = test_df.pop('cnt')\n",
    "y_test_log = test_df.pop('log_cnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test_raw.values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.copy()\n",
    "x_test = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    score = pd.DataFrame([mape, mae, mse], index=['mape', 'mae', 'mse'], columns=['score']).T\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험 설정\n",
    "- 위에서 ex = Experiment('nyc-demand-prediction', interactive=True)했는데, ex.config로 설정을 저장\n",
    "- ex.capture는 해당 설정을 사용해 함수를 리턴\n",
    "- ex.main은 실험이 실행될 때 진행할 내용을 담음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.config\n",
    "def config():\n",
    "    fit_intercept=True\n",
    "    normalize=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.capture\n",
    "def get_model(fit_intercept, normalize):\n",
    "    return LinearRegression(fit_intercept, normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _log과 _run은 별도로 정의하지 않아도 함수의 인자로 사용 가능\n",
    "@ex.main\n",
    "def run(_log, _run):\n",
    "    lr_reg = get_model()\n",
    "    lr_reg.fit(x_train, y_train_raw)\n",
    "    pred = lr_reg.predict(x_test)\n",
    "    # log File에 로그 저장\n",
    "    _log.info(\"Predict End\")\n",
    "    score = evaluation(y_test_raw, pred)\n",
    "    _run.log_scalar('model_name', lr_reg.__class__.__name__)\n",
    "    \n",
    "    # Metrics쪽에 저장하고 싶으면 아래처럼 사용\n",
    "    _run.log_scalar('metrics', score)\n",
    "    \n",
    "    # Result쪽에 저장하고 싶으면 아래처럼 사용\n",
    "    return score.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - nyc-demand-prediction - Running command 'run'\n",
      "INFO - nyc-demand-prediction - Started run with ID \"4\"\n",
      "INFO - run - Predict End\n",
      "INFO - nyc-demand-prediction - Result: {'mape': {'score': 4379287.123290663}, 'mae': {'score': 44848.791441706235}, 'mse': {'score': 1907131268986.4849}}\n",
      "INFO - nyc-demand-prediction - Completed after 0:00:01\n"
     ]
    }
   ],
   "source": [
    "experiment_result = ex.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_intercept': True, 'normalize': False, 'seed': 515113179}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_result.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 확인하기 위한 Parser\n",
    "- Experiment에서 log찍는 방식에 따라 사용할 함수가 다름\n",
    "    - 1) _run.log_scalar에 metrics을 저장하는 경우 : 추천\n",
    "    - 2) @ex.main의 함수에 결과를 return하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) _run.log_scalar에 metrics을 저장하는 경우\n",
    "def parsing_output(ex_id):\n",
    "    with open(f'./experiments/{ex_id}/metrics.json') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    with open(f'./experiments/{ex_id}/config.json') as config_file:\n",
    "        config_data = json.load(config_file)\n",
    "    \n",
    "    output_df = pd.DataFrame(json_data['model_name']['values'], columns=['model_name'], index=['score'])\n",
    "    output_df['experiment_num'] = ex_id\n",
    "    output_df['config'] = str(config_data)\n",
    "    metric_df = pd.DataFrame(json_data['metrics']['values'][0]['values'])\n",
    "    \n",
    "    output_df = pd.concat([output_df, metric_df], axis=1)\n",
    "    output_df = output_df.round(2)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) @ex.main의 함수에 결과를 return하는 경우\n",
    "def parsing_output(ex_id):\n",
    "    with open(f'./experiments/{ex_id}/run.json') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    output = pd.DataFrame(json_data['result'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>44848.791442</td>\n",
       "      <td>4.379287e+06</td>\n",
       "      <td>1.907131e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mae          mape           mse\n",
       "score  44848.791442  4.379287e+06  1.907131e+12"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsing_output(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
