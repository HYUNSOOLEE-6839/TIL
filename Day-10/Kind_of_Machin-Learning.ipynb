{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine-Learning의 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형 회귀분석(Linear Regression)\n",
    "- 직선을 그어서 그 직선 X를 통해 Y를 예측하는 것.\n",
    "- 독립변수와 종속변수가 선형적인 관계가 있다라는 가정 하에 분석\n",
    "- 직선을 통해 종속변수를 예측하기 때문에 독립변수의 중요도와 영향력을 파악하기 쉬움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 의사결정나무(Decision Tree)\n",
    "- 독립 변수의 조건에 따라 종속변수를 분리(비가 내린다 -> 축구를 하지 않는다)\n",
    "- 이해하기 쉬우나 overfitting(과적합)이 잘 일어남\n",
    "- 과적합이란?\n",
    "    - 학습데이터에 너무 잘 맞아서 실제 데이터에는 맞지 않는 것."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN (K-Nearest Neighbor)\n",
    "- 새로 들어온 데이터의 주변 k개의 데이터의 class로 분류하는 기법\n",
    "- 여기서 'k'개는 사람이 지정해줘야 하는 것이며, 이런 것들을 hyper parameter라고 함. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "- 입력, 은닉, 출력층으로 구성된 모형으로서 각 층을 연결하는 노드의 가중치를 업데이트하면서 학습\n",
    "- Overfitting이 심하게 일어나고 학습 시간이 매우 오래 걸림."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM(Support Vector Machine)\n",
    "- Class간의 거리(margin)가 최대가 되도록 decision boundary를 만드는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Learning\n",
    "- 여러 개의 모델을 결합하여 사용하는 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means clustering\n",
    "- Label 없이 데이터의 군집으로 k개 생성\n",
    "- 여기서 K 또한 사람이 설정해주어야 하는 Hyper-parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 주요 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning\n",
    "- 다층의 layer를 통해 복잡한 데이터의 학습이 가능토록 함.\n",
    "- 알고리즘 및 GPU의 발전이 deep learning의 부흥을 이끔\n",
    "- 다양한 형태로 발전 (CNN, RNN, AutoEncoder 등)\n",
    "- 네트워크 구조의 발전(ResNET, DenseNET 등)\n",
    "- 네트워크 초기화 기법 (Xavier, he initialization 등)\n",
    "- 다양한 activation function (ReLu, ELU, SeLU, Leaky ReLU 등)\n",
    "- Generalization, overfitting에 관한 문제\n",
    "- Semi-supervised learning, Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미지 분류에서 기존 모델\n",
    "    - 각각의 픽셀 값을 독립변수로 사용\n",
    "    - 독립변수들은 각각 독립이라는 기본적인 가정에서 어긋남."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN\n",
    "- 이미지의 지역별 feature를 뽑아서 neural network 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN(Generative Adversarial Network)\n",
    "- Data를 만들어내는 Generator와 만들어진 data를 평가하는 Discriminator가 서로 대립적으로 학습해가며 성능을 점차 개선해 나가자는 개념.\n",
    "<br>\n",
    "- Discriminator를 학습시킬 때에는 D(x)가 1이 되고 D(G(z))가 0이 되도록 학습시킴. \n",
    "        -(x)는 real data, (z)는 fake data.\n",
    "    - (진짜 데이터를 진짜로 판별하고, 가짜 데이터를 가짜로 판별할 수 있도록)\n",
    "- Generator를 학습시킬 때에는 D(G(z))가 1이 되도록 학습시킴\n",
    "    - (가짜 데이터를 discriminator가 구분 못 하도록 학습, discriminator를 헷갈리게 하도록)\n",
    "<br><br>\n",
    "- 여지껏 했던 분류와는 다르게 생성하는 모델임. \n",
    "- Generator와 Discriminator는 Neural Network임. 서로 학습하며 싸워 성능향상도모."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 강화학습\n",
    "- Q-learning\n",
    "    - 현재 상태에서부터 먼 미래까지 가장 큰 보상을 얻을 수 잇는 행동을 학습하게 하는 것\n",
    "    - Q-learning + Deep Learning : DQN \n",
    "<br>\n",
    "- Deep Reinforcement Learning\n",
    "    - 더 효율적으로 빠르게 학습 할 수 있는 강화학습 모델\n",
    "    - Action이 continuous 한 경우\n",
    "    - Reward가 매우 sparse한 경우\n",
    "    - Multi agent 강화학습 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모형의 적합성 평가 및 실험 설계\n",
    "### 모형의 적합성을 평가하는 방법\n",
    "- 학습 집합의 MSE는 복잡한 모형일 수록 감소하지만, 학습 데이터가 아닌 또 다른 데이터(검증 데이터)의 MSE는 일정 시점 이후로 증가.\n",
    "- 증가하는 원인은 모형이 학습 집합에 과적합 되기 때문.\n",
    "    - 가장 낮은 복잡도를 가지면 편파성이 높아져 가장 높은 MSE 값을 가짐.\n",
    "        > underfitting 되었다고 함.\n",
    "    - 가장 높은 복잡도를 가지면 학습 집합에 과적합되어 분산이 높아짐.\n",
    "        > 과적합\n",
    "- 복잡한 데이터일 수록 학습데이터는 잘 맞는다.\n",
    "<br>\n",
    "            * MSE : mean squared error, 낮을 수록 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 분할\n",
    "    - 과적합을 방지하기 위해 전체 데이터를 학습, 검증, 테스트데이터로 나누며 대개 비율은 5:3:2.\n",
    "            > 학습 데이터 : 모형 f를 추정하는데 필요.\n",
    "            > 검증 데이터 : 추정한 모형 f가 적합한지 검증함.\n",
    "            > 테스트 데이터 : 최종적으로 선택한 모형의 성능을 평가.\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold 교차검증\n",
    "- 모형의 적합성을 보다 객관적으로 평가하기 위한 방법\n",
    "- 데이터를 k(주로 5 또는 10)개 부분으로 나눈 뒤, 그 중 하나를 검증 집합, 나머지를 학습 집합으로 분류.\n",
    "- 위 과정을 k번 반복하고 k개의 성능 지표를 평균하여 모형의 적합성을 평가."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOOCV(Leave-One-Out Cross Validation)\n",
    "- 데이터의 수가 적을 때 사용하는 교차검증 방법\n",
    "- 총 n(데이터 수)개의 모델을 만드는데, 각 모델은 하나의 샘플만 제외하면서 모델을 만들고 제외한 샘플로 성능 지표를 계산함.\n",
    "- 이렇게 도출된 n개의 성능 지표를 평균 내어 최종 성능 지표를 도출\n",
    "- 즉, n-Fold cross Validation.\n",
    "- 데이터가 적은 경우 적합한 모델임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모형의 적합성 평가 및 실험 설계과정\n",
    "- 전처리\n",
    "    - Raw 데이터를 모델링 할 수 있도록 데이터를 병합 및 파생 변수 생성\n",
    "- 실험설계\n",
    "    - 실험설계에서 test데이터는 실제로 우리가 모델을 적용을 한다는 가정하여야 함.\n",
    "    - Train, validation 데이터에 test 정보는 없어야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과적합이란?\n",
    "- 복잡한 모형일 수록, 데이터가 적을 수록, 과적합이 일어나기 쉬움.\n",
    "- 학습 데이터에 너무 잘 맞고, 검증 데이터와 테스트 데이터와 잘 맞지 않는 것."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분산과 편파성(Bias)의 트레이드오프 (Dilema)\n",
    "- 모형 f^(X)로 모집단의 전체 데이터를 예측할 때 발생하는 총 error를 계산하면,\n",
    "- reducible error와 irreducible error로 표현되며,\n",
    "- reducible error는 다시 분산과 편파성으로 구성.\n",
    "<br>\n",
    "- 분산 : 전체 데이터 집합 중 다른 학습 데이터를 이용했을 때, f^이 변하는 정도.(복잡한 모형일 수록 분산이 높다.)\n",
    "- 편파성 : 학습 알고리즘에서 잘못된 가정을 했을 때 발생하는 오차(간단한 모형일 수록 편파성이 높음)\n",
    "- 복잡한 모형 f^(X)을 사용하여 편파성을 줄이면, 반대로 분산이 커짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
